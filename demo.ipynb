{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook demonstrates how to use our interface to 1) build a case base and a set of queries from a dataframe, 2) apply Case Base Maintenance (CBM) - Modified Condensed Nearest Neighbor (MCNN) method to reduce the case base size, 3) retrieve the top-k most similar cases to a query from both case bases, 4) and evaluate the similarity and diversity of the retrievals from both case bases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load data and build the original case base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils.case import Query\n",
    "from utils.casebase import CaseBase, MCNN_CaseBase\n",
    "from utils.utils import retrieve_topk\n",
    "from utils.eval import cal_diversity, cal_sim_matrix\n",
    "\n",
    "# Modify to your own path\n",
    "path = r'/home/dwd/proj/Diversity-Improvement-in-CBR/CleanedDATA V12-05-2021.csv'\n",
    "df = pd.read_csv(path, sep=';', encoding='windows-1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Uncomment line 11 to save the modification. Remove this cell once the update of data is done.\n",
    "series = df['Publication identifier,,,,,,,,,,,,,,,,,,']\n",
    "for i in range(len(series)):\n",
    "    j_comma = series[i].find(',')\n",
    "    if j_comma > 0:\n",
    "        series[i] = series[i][:j_comma]\n",
    "df.rename(columns={'Publication identifier,,,,,,,,,,,,,,,,,,': 'Publication identifier'}, inplace=True)\n",
    "# df.to_csv(path, sep=';', index=False, encoding='windows-1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cases in the dataset: 263\n",
      "Number of cases used to build the case base: 210\n",
      "Number of cases to retrieve: 5\n",
      "Attributes for case: ['Task', 'Case study type', 'Case study', 'Online/Off-line', 'Input for the model', 'Model Approach', 'Model Type', 'Models', 'Data Pre-processing', 'Complementary notes', 'Publication identifier', 'Performance indicator', 'Performance', 'Publication Year']\n",
      "Attributes for description part: ['Task', 'Case study type', 'Case study', 'Online/Off-line', 'Input for the model']\n",
      "Attributes for solution part: ['Model Approach', 'Model Type', 'Models', 'Data Pre-processing', 'Complementary notes', 'Publication identifier', 'Performance indicator', 'Performance', 'Publication Year']\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters here.\n",
    "rand_seed = 0 # provide determinism\n",
    "n_cases = int(0.8 * len(df))\n",
    "n_queries = len(df) - n_cases\n",
    "k = 5 # number of cases to retrieve\n",
    "thr_desc=0.7 # modify this threshold for MCNN's description similarity\n",
    "thr_sol=0.7 # modify this threshold for MCNN's solution similarity\n",
    "attr_names = ['Task', 'Case study type', 'Case study', 'Online/Off-line', 'Input for the model',\n",
    "              'Model Approach', 'Model Type', 'Models', 'Data Pre-processing', 'Complementary notes', 'Publication identifier',\n",
    "              'Performance indicator', 'Performance', 'Publication Year']\n",
    "desc_attrs=attr_names[:5]\n",
    "sol_attrs=attr_names[5:]\n",
    "df = df[attr_names]\n",
    "\n",
    "print(f\"Number of cases in the dataset: {len(df)}\")\n",
    "print(f\"Number of cases used to build the case base: {n_cases}\")\n",
    "print(f\"Number of cases to retrieve: {k}\")\n",
    "print(f\"Attributes for case: {attr_names}\")\n",
    "print(f\"Attributes for description part: {desc_attrs}\")\n",
    "print(f\"Attributes for solution part: {sol_attrs}\")\n",
    "\n",
    "# shuffle the rows of df\n",
    "df_ = df.sample(frac=1, random_state=rand_seed).reset_index(drop=True)\n",
    "df_cases = df_.iloc[:n_cases]\n",
    "df_queries = df_.iloc[n_cases:][desc_attrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the case base: 210\n",
      "Number of queries: 53\n"
     ]
    }
   ],
   "source": [
    "# Build the original case base from 80% of the data\n",
    "cb = CaseBase.from_dataframe(df_cases)\n",
    "print(f'Size of the case base: {len(cb.cases)}')\n",
    "\n",
    "# Create the queries using the remaining 20% of the data\n",
    "queries = []\n",
    "for i in range(len(df_queries)):\n",
    "    q = Query.from_series(df_queries.iloc[i], _id=i)\n",
    "    queries.append(q)\n",
    "print(f'Number of queries: {len(queries)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Retrieve the top-k most similar cases to the query from original case base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrive top-5 most similar cases to the query: Query 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(Case 27, 0.96),\n",
       " (Case 54, 0.96),\n",
       " (Case 74, 0.96),\n",
       " (Case 97, 0.96),\n",
       " (Case 110, 0.96)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved cases: [Case 27, Case 54, Case 74, Case 97, Case 110]\n",
      "Retrieved solutions: [Solution 27, Solution 54, Solution 74, Solution 97, Solution 110]\n",
      "Similarity list: [0.96, 0.96, 0.96, 0.96, 0.96]\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the top-5 most similar cases to the query.\n",
    "query = queries[1]\n",
    "case_sims = retrieve_topk(query, cb, weights=[1, 1, 1, 1, 1], k=k)\n",
    "print(f\"Retrive top-5 most similar cases to the query: {query}\")\n",
    "display(case_sims)\n",
    "# Extract the retrieved case and similarity list from the result\n",
    "retrieved_cases0 = list(map(lambda x: x[0], case_sims))\n",
    "retrieved_solutions0 = list(map(lambda x: x.to_desc_sol_pair(desc_attrs, sol_attrs)[1], retrieved_cases0))\n",
    "retrieved_sims0 = list(map(lambda x: x[1], case_sims))\n",
    "print(f\"Retrieved cases: {retrieved_cases0}\")\n",
    "print(f\"Retrieved solutions: {retrieved_solutions0}\")\n",
    "print(f\"Similarity list: {retrieved_sims0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Apply Case Base Maintenance (CBM) method - Modified Condensed Nearest Neighbor (MCNN).\n",
    "The new case base is built from exactly the same cases as the original case base, with generalization of descriptions and solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of descriptions in new case base: 12\n",
      "Number of solutions in new case base: 34\n"
     ]
    }
   ],
   "source": [
    "# Initialize the MCNN Case Base\n",
    "mcnn_cb = MCNN_CaseBase(cb.cases, desc_attrs, sol_attrs, thr_desc, thr_sol=thr_sol, \n",
    "                        _seed=rand_seed)\n",
    "\n",
    "print(\"Number of descriptions in new case base:\", len(mcnn_cb.descriptions))\n",
    "print(\"Number of solutions in new case base:\", len(mcnn_cb.solutions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Retrieve the top-k most similar cases to the query from new case base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrive top-5 most similar cases to the query: Query 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[((GC 104, Solution 104), 0.8965000000000001),\n",
       " ((GC 104, Solution 43), 0.8965000000000001),\n",
       " ((GC 104, Solution 13), 0.8965000000000001),\n",
       " ((GC 104, Solution 51), 0.8965000000000001),\n",
       " ((GC 104, Solution 196), 0.8965000000000001)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved solutions: [Solution 104, Solution 43, Solution 13, Solution 51, Solution 196]\n",
      "Similarity list: [0.8965000000000001, 0.8965000000000001, 0.8965000000000001, 0.8965000000000001, 0.8965000000000001]\n"
     ]
    }
   ],
   "source": [
    "rlt = mcnn_cb.retrieve_topk(query, k=k)\n",
    "print(f\"Retrive top-5 most similar cases to the query: {query}\")\n",
    "display(rlt)\n",
    "# Extract the retrieved solution and similarity list from the result\n",
    "retrieved_solutions1 = list(map(lambda x: x[0][1], rlt))\n",
    "retrieved_sims1 = list(map(lambda x: x[1], rlt))\n",
    "print(\"Retrieved solutions:\", retrieved_solutions1)\n",
    "print(\"Similarity list:\", retrieved_sims1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluate and compare the results of the two retrievals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Original Case Base =========\n",
      "Similarity matrix:\n",
      "[[1.         0.96666667 0.70913037 0.96666667 0.96666667]\n",
      " [0.96666667 1.         0.70913037 0.96666667 0.96666667]\n",
      " [0.70913037 0.70913037 1.         0.70913037 0.70913037]\n",
      " [0.96666667 0.96666667 0.70913037 1.         0.96666667]\n",
      " [0.96666667 0.96666667 0.70913037 0.96666667 1.        ]]\n",
      "---------------------------------\n",
      "Average similarity: 0.96\n",
      "Diversity: 0.272695707070707\n",
      "\n",
      "============ MCNN Case Base ===========\n",
      "Similarity matrix:\n",
      "[[1.         0.66821705 0.6666559  0.62436647 0.50756303]\n",
      " [0.66821705 1.         0.60844631 0.56929825 0.60213033]\n",
      " [0.6666559  0.60844631 1.         0.55065789 0.43472222]\n",
      " [0.62436647 0.56929825 0.55065789 1.         0.42358674]\n",
      " [0.50756303 0.60213033 0.43472222 0.42358674 1.        ]]\n",
      "---------------------------------\n",
      "Average similarity: 0.8965\n",
      "Diversity: 0.8688711621042963\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average similarity and diversity of the retrieved cases\n",
    "aver_sim0 = sum(retrieved_sims0) / len(retrieved_sims0)\n",
    "sim_matrix0 = cal_sim_matrix(retrieved_solutions0, case_base=cb)\n",
    "div0 = cal_diversity(sim_matrix0)\n",
    "print(\"========== Original Case Base =========\")\n",
    "print(\"Similarity matrix:\")\n",
    "print(sim_matrix0)\n",
    "print(\"---------------------------------\")\n",
    "print(\"Average similarity:\", aver_sim0)\n",
    "print(\"Diversity:\", div0)\n",
    "\n",
    "# Calculate the average similarity and diversity of the retrieved solutions\n",
    "aver_sim1 = sum(retrieved_sims1) / len(retrieved_sims1)\n",
    "# NOTE: The similarity matrix can be useful when implementing the other CBM methods\n",
    "# Calculate the inter-solution similarities\n",
    "sim_matrix1 = cal_sim_matrix(retrieved_solutions1, case_base=mcnn_cb)\n",
    "div1 = cal_diversity(sim_matrix1)\n",
    "print(\"\\n============ MCNN Case Base ===========\")\n",
    "print(\"Similarity matrix:\")\n",
    "print(sim_matrix1)\n",
    "print(\"---------------------------------\")\n",
    "print(\"Average similarity:\", aver_sim1)\n",
    "print(\"Diversity:\", div1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODOs:\n",
    "- Unify performance metrics for the solutions (utils/case.py, line 182)\n",
    "- Implement the other CBM methods\n",
    "- Implement the other case base evaluation metrics (coverage, etc.)\n",
    "- GUI + Batch test + Results visualization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
